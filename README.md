# ICU-Mortality-Prediction
ICU Mortality Prediction using XGBoost, Decision Trees and Logistic Regression. Comparison of results.

**Introduction**

Severity of illness has been traditionally linked with mortality risk. However, the relationship of severity of illness with mortality likely differs across ICUs based on a host of factors, including but not limited to staffing, capacity for special diagnostic tests and interventions, and variation in the culture of quality and patient safety. While, in theory, one would think that physiology transcends geography, differences in care systems and patient populations may translate the same score to very different outcomes. Put simply, an illness's severity translates into different mortality risks depending on where the patient is located. The first 24 hours in an ICU are crucial for any patient. It is during this stage that various preliminary diagnostic tests are conducted and appropriate steps are taken to treat the patient in the most efficient manner possible. The goal of this project is to hence develop a system to predict the survival of a patient admitted to Intensive Care Unit (ICU) using the parameters obtained through initial tests. 
Various machine learning algorithms were implemented including Logistic Regression, Decision Trees and XGBoost algorithms. Initial dataset was skewed and hence treated using oversampling and undersampling and the results from these were further observed on the above-mentioned algorithms. Lastly, a comparison of the results using appropriate metrics like ROC-AUC score and F1 score to derive useful conclusions. 

**Dataset Description**

The dataset has been released as open source by MIT’s GOSSIS community initiative, with privacy certification from the Harvard Privacy Lab. The dataset consists of more than 130,000 hospital Intensive Care Unit (ICU) visits from patients, spanning a one-year timeframe at various hospitals located in Argentina, Australia, New Zealand, Sri Lanka, Brazil, and more than 200 hospitals in the United States. The dataset consists of 186 attributes and 91713 instances – out of which 15 are categorical and 171 are of numerical type. The target attribute we are trying to predict in ‘hospitaldeath’ – 1 implies death and 0 implies survival. Out of the 91713 instances in our dataset - 83798 entries correspond to a survival 7915 entries correspond to a death. As we can see, the dataset is skewed and this is addressed in the following sections. 

**Conclusion**

The Logistic Regression and Decision Tree algorithms perform well in accuracy on the whole dataset but fail to predict a death with proper precision when original data is used. Undersampling and Oversampling solve the metric problem to an extent when we deal with an unbalanced dataset, but they add their own baggage - undersampling results in data loss and oversampling creates lots of false data. The effects of sampling differ for each technique; some algorithms work better with undersampled data and some algorithms work better on oversampled data. ROC-AUC score is taken as a metric when class imbalance is present. XGBoost successfully boosts both the ROC and F1 scores. Recursive Feature Elimination results in a subset of features that give comparable metric values when compared with the results associated with the original set of columns. All the models make better generalizations when sampling techniques are applied to this problem. It betters the model’s capacity of predicting mortality for a patient appropriately. 
